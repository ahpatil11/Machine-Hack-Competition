{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model    \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 693,601\n",
      "Trainable params: 693,089\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), input_shape = (128, 128, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3),  activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3),  activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3),  activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                   shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9471 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('Train', target_size=(128, 128), batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Test', target_size=(128, 128), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "296/296 [==============================] - 211s 713ms/step - loss: 0.9484 - accuracy: 0.5822\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 196s 662ms/step - loss: 0.6323 - accuracy: 0.6561\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 194s 654ms/step - loss: 0.5828 - accuracy: 0.6921\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 207s 698ms/step - loss: 0.5652 - accuracy: 0.7034\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 188s 636ms/step - loss: 0.5465 - accuracy: 0.7186\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 166s 560ms/step - loss: 0.5268 - accuracy: 0.7378\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 167s 565ms/step - loss: 0.5166 - accuracy: 0.7436\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 153s 515ms/step - loss: 0.5030 - accuracy: 0.7505\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 153s 518ms/step - loss: 0.4977 - accuracy: 0.7570\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 154s 520ms/step - loss: 0.4826 - accuracy: 0.7663\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 150s 508ms/step - loss: 0.4701 - accuracy: 0.7714\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 159s 537ms/step - loss: 0.4578 - accuracy: 0.7864\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 166s 561ms/step - loss: 0.4491 - accuracy: 0.7882\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 167s 564ms/step - loss: 0.4312 - accuracy: 0.7945\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 161s 545ms/step - loss: 0.4213 - accuracy: 0.8034\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 147s 496ms/step - loss: 0.3990 - accuracy: 0.8184\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 148s 499ms/step - loss: 0.3906 - accuracy: 0.8217\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 145s 491ms/step - loss: 0.3794 - accuracy: 0.8272\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 146s 494ms/step - loss: 0.3711 - accuracy: 0.8306\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 145s 491ms/step - loss: 0.3667 - accuracy: 0.8348\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 146s 494ms/step - loss: 0.3618 - accuracy: 0.8344\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 149s 504ms/step - loss: 0.3604 - accuracy: 0.8375\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 148s 501ms/step - loss: 0.3438 - accuracy: 0.8406\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 144s 487ms/step - loss: 0.3397 - accuracy: 0.8521\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 148s 500ms/step - loss: 0.3364 - accuracy: 0.8464\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 151s 510ms/step - loss: 0.3321 - accuracy: 0.8489\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 152s 513ms/step - loss: 0.3286 - accuracy: 0.8550\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 158s 535ms/step - loss: 0.3185 - accuracy: 0.8626\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 160s 540ms/step - loss: 0.3104 - accuracy: 0.8644\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 155s 522ms/step - loss: 0.3128 - accuracy: 0.8609\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 181s 612ms/step - loss: 0.3065 - accuracy: 0.8653\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 178s 603ms/step - loss: 0.3086 - accuracy: 0.8662\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 181s 610ms/step - loss: 0.2990 - accuracy: 0.8695\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 180s 608ms/step - loss: 0.2996 - accuracy: 0.8700\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 181s 611ms/step - loss: 0.2962 - accuracy: 0.8738\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 179s 606ms/step - loss: 0.2851 - accuracy: 0.8755\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 180s 609ms/step - loss: 0.2880 - accuracy: 0.8732\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 180s 607ms/step - loss: 0.2880 - accuracy: 0.8744\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 181s 611ms/step - loss: 0.2770 - accuracy: 0.8782\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 180s 608ms/step - loss: 0.2808 - accuracy: 0.8776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fcc7693fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set, epochs=40, validation_data=test_set, validation_steps=11)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = plt.imread('Test/320.jpg') \n",
    "img = cv2.resize(img,(128,128))\n",
    "img = np.expand_dims(img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
